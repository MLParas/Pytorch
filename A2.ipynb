{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYsl3k_ZeI5O",
        "outputId": "35f008db-c046-4247-a7a1-8eb5ed45cfc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# For reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading CIFAR 10 data"
      ],
      "metadata": {
        "id": "9NQn0NNAeNcS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NPGRxjofmSgq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(train_batch_size=128,test_batch_size=256,Sr=1.0,num_workers=2):\n",
        "\n",
        "    # Standard transformations (https://github.com/moritzhambach/Image-Augmentation-in-Keras-CIFAR-10-) normalisation matrices taken from here\n",
        "    x = (0.4914, 0.4822, 0.4465)\n",
        "    y = (0.2470, 0.2435, 0.2616)\n",
        "    transform_train = transforms.Compose([transforms.RandomHorizontalFlip(),transforms.RandomCrop(32, padding=4),transforms.ToTensor(),transforms.Normalize(x,y)])\n",
        "    transform_test = transforms.Compose([transforms.ToTensor(),transforms.Normalize(x,y)])\n",
        "\n",
        "    # Download and create datasets\n",
        "    X_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    X_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "    # Sample data\n",
        "    N = int(len(X_train) * Sr)\n",
        "    X_f,_ = random_split(X_train, [N, len(X_train)-N])\n",
        "\n",
        "    #Load data\n",
        "    tr = DataLoader(X_f,batch_size=train_batch_size,shuffle=True, num_workers=num_workers)\n",
        "    ts = DataLoader(X_test,batch_size=test_batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return tr, ts"
      ],
      "metadata": {
        "id": "f9MYMWB0tGEw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "\n",
        "    def __init__(self,image_size = 32, in_channels=3, patch_size=4, emb_dim=128, stride=None):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.image_size = 32\n",
        "        if stride is None:\n",
        "            stride = patch_size  # no overlap\n",
        "        self.unfold = nn.Unfold(kernel_size=patch_size, stride=stride)\n",
        "        self.linear = nn.Linear(in_channels * patch_size * patch_size, emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, H, W)\n",
        "        patches = self.unfold(x)\n",
        "        patches = patches.transpose(1, 2)\n",
        "        embeds = self.linear(patches)  # (B, Num_Patches, emb_dim)\n",
        "        return embeds\n",
        "\n",
        "\n",
        "# Pytorch has a module but I wrote it myself because of diff input params i passed\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, emb_dim, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = emb_dim // num_heads\n",
        "        E = emb_dim\n",
        "        self.projections = nn.ModuleList([nn.Linear(E, E) for _ in range(3)])\n",
        "        self.out = nn.Linear(E, E)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, N, emb_dim) where N=number of patches+1 if CLS token is included\n",
        "        B, N, _ = x.shape\n",
        "\n",
        "        # Linear projections\n",
        "        Q = self.projections[0](x)\n",
        "        K = self.projections[1](x)\n",
        "        V = self.projections[2](x)\n",
        "\n",
        "        # Reshape to multi-head\n",
        "        Q = Q.reshape(B, N, self.num_heads, self.head_dim).transpose(1, 2)  # (B, num_heads, N, head_dim)\n",
        "        K = K.reshape(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V = V.reshape(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # self attention\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        attn = scores.softmax(dim=-1)\n",
        "        out = torch.matmul(attn, V)\n",
        "        out = out.transpose(1, 2).reshape(B, N, -1)  # (B, N, emb_dim)\n",
        "\n",
        "        # Final\n",
        "        out = self.out(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out, attn"
      ],
      "metadata": {
        "id": "pP41VWyer0Wz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, emb_dim, num_heads=4, mlp_ratio=4.0, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # attention\n",
        "        self.msa = MultiHeadSelfAttention(emb_dim, num_heads, dropout)\n",
        "        #layr norms\n",
        "        self.ln1 = nn.LayerNorm(emb_dim)\n",
        "        self.ln2 = nn.LayerNorm(emb_dim)\n",
        "        h = int(emb_dim * mlp_ratio)\n",
        "        self.mlp = nn.Sequential(nn.Linear(emb_dim, h),nn.GELU(),nn.Dropout(dropout),nn.Linear(h, emb_dim),nn.Dropout(dropout) )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Attention\n",
        "        out, attn = self.msa(self.ln1(x))\n",
        "        x = x + out\n",
        "        # MLP\n",
        "        out = self.mlp(self.ln2(x))\n",
        "        x = x + out\n",
        "\n",
        "        return x, attn"
      ],
      "metadata": {
        "id": "-f_Ov6ZUJLBA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ViT Model Combined"
      ],
      "metadata": {
        "id": "X7bgV-LlJSUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, image_size=32, patch_size=4, stride=None, in_channels=3, emb_dim=128, depth=6, num_heads=4, mlp_ratio=4, num_classes=10, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Patch embedding\n",
        "        self.patch_embed = PatchEmbed(image_size,in_channels, patch_size, emb_dim, stride)\n",
        "\n",
        "        if stride is None:\n",
        "            stride = patch_size\n",
        "        num_h = (image_size - patch_size)//stride + 1\n",
        "        num_w = (image_size - patch_size)//stride + 1\n",
        "        self.num_patches = num_h * num_w\n",
        "\n",
        "        # CLS & posn embeds\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, emb_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, self.num_patches + 1, emb_dim))\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
        "        self.pos_drop = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Tx block and LN\n",
        "        self.blocks = nn.ModuleList([TransformerEncoderBlock(emb_dim, num_heads, mlp_ratio, dropout) for _ in range(depth)])\n",
        "        self.ln = nn.LayerNorm(emb_dim)\n",
        "        self.fc = nn.Linear(emb_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, return_attention=False):\n",
        "        \"\"\"\n",
        "        return_attention: if True, returns the attention maps from each block\n",
        "                          for visualization.\n",
        "        \"\"\"\n",
        "        B = x.size(0)\n",
        "        x = self.patch_embed(x)\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)  # (B, 1, emb_dim)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)  # (B, 1+Num_Patches, emb_dim)\n",
        "\n",
        "        # concatening post to x\n",
        "        x = x + self.pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        attn_maps = []\n",
        "\n",
        "        # Pass through transformer blocks\n",
        "        for blk in self.blocks:\n",
        "            x, attn = blk(x)\n",
        "            if return_attention:\n",
        "                attn_maps.append(attn)\n",
        "\n",
        "        # Classification using the CLS token\n",
        "        # x = self.ln(x)\n",
        "        # cls_out = x[:, 0]  # (B, emb_dim)\n",
        "        # logits = self.fc(cls_out)  # (B, num_classes)\n",
        "\n",
        "        # if return_attention:\n",
        "        #     return logits, attn_maps\n",
        "        # else:\n",
        "        #     return logits\n",
        "        logits = self.fc(self.ln(x)[:, 0])  # Final Layer Norm + CLS token for classification\n",
        "        return (logits, attn_maps) if return_attention else logits"
      ],
      "metadata": {
        "id": "W5tiYcBTsy-r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RnJ6pC7aJRMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss,correct,total = 0,0,0\n",
        "\n",
        "    for X, y in dataloader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(X)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * X.size(0)\n",
        "        _, preds = out.max(1)\n",
        "        correct += preds.eq(y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def test_one_epoch(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss,correct,total = 0,0,0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "            total_loss += loss.item() * X.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=10, lr=3e-4):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "        te_loss, te_acc = test_one_epoch(model, test_loader, criterion)\n",
        "\n",
        "        train_losses.append(tr_loss)\n",
        "        train_accs.append(tr_acc)\n",
        "        test_losses.append(te_loss)\n",
        "        test_accs.append(te_acc)\n",
        "\n",
        "        print(f\"[Epoch {epoch+1}/{epochs}] \"\n",
        "              f\"Train Loss: {tr_loss:.4f} | Train Acc: {tr_acc:.2f}% || \"\n",
        "              f\"Test Loss: {te_loss:.4f} | Test Acc: {te_acc:.2f}%\")\n",
        "\n",
        "    return train_losses, train_accs, test_losses, test_accs"
      ],
      "metadata": {
        "id": "AlsUwPn3s8kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D1vst_cTs96z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 1:"
      ],
      "metadata": {
        "id": "NV7AoKoEeFh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "# Load CIFAR-10 dataset (100% training data)\n",
        "train_loader_full, test_loader_full = get_data(train_batch_size=128, test_batch_size=256, Sr=1.0)\n",
        "\n",
        "# Initialize Vision Transformer (ViT)\n",
        "model_vit = VisionTransformer(image_size=32, patch_size=4, stride=4, in_channels=3, emb_dim=128, depth=6, num_heads=4, mlp_ratio=4.0, num_classes=10, dropout=0.1)\n",
        "\n",
        "# Train the model\n",
        "train_losses, train_accs, test_losses, test_accs = train_model(model_vit, train_loader_full, test_loader_full, epochs=20, lr=3e-4)\n",
        "\n",
        "\n",
        "# Plot training curve\n",
        "plt.figure()\n",
        "plt.plot(train_accs, label='Train Accuracy')\n",
        "plt.plot(test_accs, label='Test Accuracy')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy vs Epochs (ViT on CIFAR-10)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bm1sPl1-tNza",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "outputId": "db346b46-000f-42c2-c00a-e97ee8c4ef92"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 29.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "[Epoch 1/20] Train Loss: 1.7944 | Train Acc: 32.81% || Test Loss: 1.6514 | Test Acc: 39.64%\n",
            "[Epoch 2/20] Train Loss: 1.5004 | Train Acc: 44.86% || Test Loss: 1.3701 | Test Acc: 50.16%\n",
            "[Epoch 3/20] Train Loss: 1.3565 | Train Acc: 50.48% || Test Loss: 1.2560 | Test Acc: 54.49%\n",
            "[Epoch 4/20] Train Loss: 1.2597 | Train Acc: 54.39% || Test Loss: 1.1853 | Test Acc: 56.85%\n",
            "[Epoch 5/20] Train Loss: 1.1861 | Train Acc: 57.12% || Test Loss: 1.1208 | Test Acc: 59.17%\n",
            "[Epoch 6/20] Train Loss: 1.1314 | Train Acc: 59.05% || Test Loss: 1.0701 | Test Acc: 60.91%\n",
            "[Epoch 7/20] Train Loss: 1.0854 | Train Acc: 61.18% || Test Loss: 1.0159 | Test Acc: 63.47%\n",
            "[Epoch 8/20] Train Loss: 1.0444 | Train Acc: 62.41% || Test Loss: 0.9791 | Test Acc: 64.96%\n",
            "[Epoch 9/20] Train Loss: 1.0077 | Train Acc: 63.67% || Test Loss: 0.9512 | Test Acc: 65.01%\n",
            "[Epoch 10/20] Train Loss: 0.9697 | Train Acc: 65.20% || Test Loss: 0.9168 | Test Acc: 67.38%\n",
            "[Epoch 11/20] Train Loss: 0.9399 | Train Acc: 66.29% || Test Loss: 0.9124 | Test Acc: 67.24%\n",
            "[Epoch 12/20] Train Loss: 0.9026 | Train Acc: 67.66% || Test Loss: 0.8702 | Test Acc: 68.90%\n",
            "[Epoch 13/20] Train Loss: 0.8761 | Train Acc: 69.02% || Test Loss: 0.8101 | Test Acc: 71.52%\n",
            "[Epoch 14/20] Train Loss: 0.8545 | Train Acc: 69.44% || Test Loss: 0.8231 | Test Acc: 71.23%\n",
            "[Epoch 15/20] Train Loss: 0.8317 | Train Acc: 70.39% || Test Loss: 0.7969 | Test Acc: 71.63%\n",
            "[Epoch 16/20] Train Loss: 0.8087 | Train Acc: 71.10% || Test Loss: 0.7846 | Test Acc: 72.37%\n",
            "[Epoch 17/20] Train Loss: 0.7878 | Train Acc: 71.89% || Test Loss: 0.7548 | Test Acc: 73.08%\n",
            "[Epoch 18/20] Train Loss: 0.7653 | Train Acc: 72.83% || Test Loss: 0.7643 | Test Acc: 73.26%\n",
            "[Epoch 19/20] Train Loss: 0.7533 | Train Acc: 73.05% || Test Loss: 0.7824 | Test Acc: 72.93%\n",
            "[Epoch 20/20] Train Loss: 0.7343 | Train Acc: 73.97% || Test Loss: 0.7173 | Test Acc: 75.15%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot train and test losses\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_losses, marker=\"o\", linestyle=\"--\", color=\"green\", markersize=6, label=\"Train Loss\")\n",
        "plt.plot(epochs, test_losses, marker=\"s\", linestyle=\"-\", color=\"purple\", markersize=6, label=\"Test Loss\")\n",
        "\n",
        "# Formatting the plot\n",
        "plt.xlabel(\"Epoch\", fontsize=12, fontweight=\"bold\")\n",
        "plt.ylabel(\"Loss\", fontsize=12, fontweight=\"bold\")\n",
        "plt.title(\"Training and Test Loss vs Epochs\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend(fontsize=10, loc=\"upper right\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "plt.xticks(epochs)\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eIisekYzMMaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some visualisations"
      ],
      "metadata": {
        "id": "79sOvBf6gDPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 class labels\n",
        "class_labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
        "                'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "def visualize_predictions(model, dataloader, device, num_images=10):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    images, labels = next(iter(dataloader))  # Get a batch of images\n",
        "    images, labels = images[:num_images].to(device), labels[:num_images].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1)  # Get predicted class indices\n",
        "\n",
        "    # Convert images from tensor to numpy and unnormalize\n",
        "    images = images.cpu().numpy().transpose(0, 2, 3, 1)  # Convert (C, H, W) -> (H, W, C)\n",
        "    images = np.clip(images * 0.25 + 0.5, 0, 1)  # Unnormalize for display\n",
        "\n",
        "    # Improved Plot Aesthetics\n",
        "    fig, axes = plt.subplots(2, num_images // 2, figsize=(12, 6))  # 2 rows for better spacing\n",
        "    fig.suptitle(\"Vision Transformer Predictions on CIFAR-10\", fontsize=14, fontweight=\"bold\")\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(images[i])\n",
        "        pred_label = class_labels[preds[i]]\n",
        "        true_label = class_labels[labels[i]]\n",
        "        title_color = \"green\" if preds[i] == labels[i] else \"red\"\n",
        "\n",
        "        ax.set_title(f\"Pred: {pred_label}\\nGT: {true_label}\", fontsize=10, color=title_color)\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to fit title\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "-U0SYkqcgBZQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jt_Sq2VWgCWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 2 : Train your model at different data sizes 5%, 10%, 25%, 50% and 100% of the\n",
        "training dataset and discuss model performance"
      ],
      "metadata": {
        "id": "SPNUBX3RtUO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define subset sizes and an empty results dictionary\n",
        "subset_sizes = [0.05, 0.10, 0.25, 0.50, 1.0]  # 5%, 10%, 25%, 50%, 100% of training data\n",
        "results = {}\n",
        "\n",
        "for size in subset_sizes:\n",
        "    print(f\"\\nTraining on {int(size * 100)}% of CIFAR-10 dataset...\")\n",
        "\n",
        "    train_loader, test_loader = get_data(train_batch_size=128, test_batch_size=256, Sr=size)\n",
        "    model = VisionTransformer(image_size=32, patch_size=4, stride=4, in_channels=3, emb_dim=128,\n",
        "                              depth=6, num_heads=4, mlp_ratio=4.0, num_classes=10, dropout=0.1).to(device)\n",
        "\n",
        "    # Unpack full loss and accuracy arrays for each epoch\n",
        "    train_losses, train_accs, test_losses, test_accs = train_model(model, train_loader, test_loader, epochs=20, lr=3e-4)\n",
        "\n",
        "    # For accuracy, we only need the final values;\n",
        "    # For losses, we store the full arrays (loss curves)\n",
        "    results[size] = {\n",
        "        \"final_train_acc\": train_accs[-1],\n",
        "        \"final_test_acc\": test_accs[-1],\n",
        "        \"train_loss\": train_losses,\n",
        "        \"test_loss\": test_losses\n",
        "    }\n",
        "\n",
        "\n",
        "sizes = [int(s * 100) for s in subset_sizes]\n",
        "train_accs = [results[s][\"train_acc\"] for s in subset_sizes]\n",
        "test_accs = [results[s][\"test_acc\"] for s in subset_sizes]\n",
        "train_losses = [results[s][\"train_loss\"] for s in subset_sizes]\n",
        "test_losses = [results[s][\"test_loss\"] for s in subset_sizes]\n",
        "\n",
        "# Figure 1: Accuracy vs. Dataset Size\n",
        "sizes_plot = [int(s * 100) for s in subset_sizes]\n",
        "final_train_accs = [results[s][\"final_train_acc\"] for s in subset_sizes]\n",
        "final_test_accs = [results[s][\"final_test_acc\"] for s in subset_sizes]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(sizes_plot, final_train_accs, marker=\"o\", linestyle=\"--\", color=\"blue\", markersize=8, label=\"Train Accuracy\")\n",
        "plt.plot(sizes_plot, final_test_accs, marker=\"s\", linestyle=\"-\", color=\"red\", markersize=8, label=\"Test Accuracy\")\n",
        "plt.xlabel(\"Percentage of Training Data\", fontsize=12, fontweight=\"bold\")\n",
        "plt.ylabel(\"Accuracy (%)\", fontsize=12, fontweight=\"bold\")\n",
        "plt.title(\"Effect of Training Data Size on ViT Performance\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend(fontsize=10, loc=\"lower right\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "plt.xticks(sizes_plot)\n",
        "plt.ylim(30, 80)\n",
        "plt.show()\n",
        "# Figure 2: Loss vs. Dataset Size\n",
        "# Subplot 1: Training Loss Curves\n",
        "plt.subplot(1, 2, 1)\n",
        "for size in subset_sizes:\n",
        "    epochs = range(1, len(results[size][\"train_loss\"]) + 1)\n",
        "    plt.plot(epochs, results[size][\"train_loss\"], marker=\"o\", linestyle=\"--\", label=f\"{int(size*100)}%\")\n",
        "plt.xlabel(\"Epoch\", fontsize=12, fontweight=\"bold\")\n",
        "plt.ylabel(\"Train Loss\", fontsize=12, fontweight=\"bold\")\n",
        "plt.title(\"Training Loss vs. Epochs\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend(title=\"Training Data %\", fontsize=10)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "# Subplot 2: Test Loss Curves\n",
        "plt.subplot(1, 2, 2)\n",
        "for size in subset_sizes:\n",
        "    epochs = range(1, len(results[size][\"test_loss\"]) + 1)\n",
        "    plt.plot(epochs, results[size][\"test_loss\"], marker=\"s\", linestyle=\"-\", label=f\"{int(size*100)}%\")\n",
        "plt.xlabel(\"Epoch\", fontsize=12, fontweight=\"bold\")\n",
        "plt.ylabel(\"Test Loss\", fontsize=12, fontweight=\"bold\")\n",
        "plt.title(\"Test Loss vs. Epochs\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend(title=\"Training Data %\", fontsize=10)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SpyEN75BrnMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 4"
      ],
      "metadata": {
        "id": "ZZMsyNv9tX4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment: Varying Patch Sizes with Overlapping vs Non-Overlapping Conditions\n",
        "patch_sizes = [4, 8, 12, 16, 32]\n",
        "overlap_conditions = {\"Non-Overlapping\": lambda ps: ps, \"Overlapping\": lambda ps: ps // 2}\n",
        "results_patch = {}  # Key: (patch_size, condition), Value: final test accuracy\n",
        "\n",
        "for ps in patch_sizes:\n",
        "    for condition, stride_fn in overlap_conditions.items():\n",
        "        stride = stride_fn(ps)\n",
        "        print(f\"\\n=== Training with patch_size={ps} | {condition} (stride={stride}) ===\")\n",
        "        model = VisionTransformer(image_size=32, patch_size=ps, stride=stride, in_channels=3, emb_dim=128,\n",
        "                                  depth=6, num_heads=4, mlp_ratio=4.0, num_classes=10, dropout=0.1).to(device)\n",
        "        train_loader, test_loader = get_data(Sr=1)  # Using 50% of data for faster result\n",
        "        _, _, _, test_accs = train_model(model, train_loader, test_loader, epochs=20, lr=3e-4)\n",
        "        results_patch[(ps, condition)] = test_accs[-1]\n",
        "\n",
        "# Plotting the results\n",
        "# Combined Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "for condition in overlap_conditions.keys():\n",
        "    ps_vals = [ps for ps in patch_sizes]\n",
        "    acc_vals = [results_patch[(ps, condition)] for ps in patch_sizes]\n",
        "    plt.plot(ps_vals, acc_vals, marker='o', linestyle='--' if condition == \"Non-Overlapping\" else '-', label=f\"{condition} Patches\")\n",
        "\n",
        "# Formatting\n",
        "plt.xlabel(\"Patch Size\", fontsize=12, fontweight=\"bold\")\n",
        "plt.ylabel(\"Test Accuracy (%)\", fontsize=12, fontweight=\"bold\")\n",
        "plt.title(\"ViT Performance vs Patch Size (Overlapping vs Non-Overlapping)\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "plt.xticks(patch_sizes)\n",
        "plt.ylim(min(results_patch.values()) - 2, max(results_patch.values()) + 2)  # Adjusting Y-axis limits dynamically\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dco1JkwFjyfs",
        "outputId": "b541d949-f076-491e-95e6-1efca7128cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training with patch_size=4 | Non-Overlapping (stride=4) ===\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch 1/20] Train Loss: 1.7847 | Train Acc: 33.30% || Test Loss: 1.6260 | Test Acc: 40.30%\n",
            "[Epoch 2/20] Train Loss: 1.4867 | Train Acc: 45.64% || Test Loss: 1.4231 | Test Acc: 48.78%\n",
            "[Epoch 3/20] Train Loss: 1.3399 | Train Acc: 51.43% || Test Loss: 1.2689 | Test Acc: 54.44%\n",
            "[Epoch 4/20] Train Loss: 1.2437 | Train Acc: 55.01% || Test Loss: 1.1906 | Test Acc: 56.60%\n",
            "[Epoch 5/20] Train Loss: 1.1839 | Train Acc: 57.42% || Test Loss: 1.1443 | Test Acc: 58.35%\n",
            "[Epoch 6/20] Train Loss: 1.1219 | Train Acc: 59.41% || Test Loss: 1.0330 | Test Acc: 62.65%\n",
            "[Epoch 7/20] Train Loss: 1.0770 | Train Acc: 61.06% || Test Loss: 1.0440 | Test Acc: 62.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4zrb_qstbt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 4: Varying number of attention heads"
      ],
      "metadata": {
        "id": "AMD-pYRktcm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment: Varying Number of Attention Heads (Plotting Train & Test Accuracies)\n",
        "num_heads_list = [2, 4, 8]\n",
        "results_train = {}\n",
        "results_test = {}\n",
        "\n",
        "for nh in num_heads_list:\n",
        "    print(f\"\\n=== Training with {nh} Attention Heads ===\")\n",
        "    model = VisionTransformer(image_size=32, patch_size=4, stride=4, in_channels=3, emb_dim=128,\n",
        "                              depth=6, num_heads=nh, mlp_ratio=4.0, num_classes=10, dropout=0.1).to(device)\n",
        "    train_loader, test_loader = get_data(Sr=1.0)  # Using full training data\n",
        "    train_losses, train_accs, test_losses, test_accs = train_model(model, train_loader, test_loader, epochs=20, lr=3e-4)\n",
        "    results_train[nh] = train_accs[-1]\n",
        "    results_test[nh] = test_accs[-1]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(list(results_train.keys()), list(results_train.values()), marker='o', label='Train Accuracy')\n",
        "plt.plot(list(results_test.keys()), list(results_test.values()), marker='o', label='Test Accuracy')\n",
        "plt.xlabel(\"Number of Attention Heads\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"ViT Performance vs. Number of Attention Heads\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xmzgVUXktduj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NKt-MlpotfBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 5"
      ],
      "metadata": {
        "id": "vYGb7tNBu6qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 5: Classify using the CLS token from different model layers via a linear probe\n",
        "\n",
        "def get_cls_representation(model, x, layer_idx):\n",
        "    B = x.size(0)\n",
        "    # Patch embedding and adding CLS token and positional embedding\n",
        "    x = model.patch_embed(x)\n",
        "    cls_tokens = model.cls_token.expand(B, -1, -1)\n",
        "    x = torch.cat((cls_tokens, x), dim=1)\n",
        "    x = x + model.pos_embed\n",
        "    x = model.pos_drop(x)\n",
        "    # Pass through the first 'layer_idx' transformer blocks\n",
        "    for i in range(layer_idx):\n",
        "        x, _ = model.blocks[i](x)\n",
        "    # Final LayerNorm and extract CLS token\n",
        "    x = model.ln(x)\n",
        "    return x[:, 0]  # Shape: (B, emb_dim)\n",
        "\n",
        "def train_linear_probe(model, train_loader, test_loader, layer_idx, device, epochs=5, lr=1e-3):\n",
        "    model.eval()\n",
        "    train_feats, train_labels = [], []\n",
        "    test_feats, test_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            feats = get_cls_representation(model, imgs, layer_idx)\n",
        "            train_feats.append(feats.cpu())\n",
        "            train_labels.append(labels)\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            feats = get_cls_representation(model, imgs, layer_idx)\n",
        "            test_feats.append(feats.cpu())\n",
        "            test_labels.append(labels)\n",
        "    train_feats = torch.cat(train_feats)\n",
        "    train_labels = torch.cat(train_labels)\n",
        "    test_feats = torch.cat(test_feats)\n",
        "    test_labels = torch.cat(test_labels)\n",
        "\n",
        "    classifier = nn.Linear(train_feats.size(1), 10).to(device)\n",
        "    optimizer = optim.Adam(classifier.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train linear classifier (linear probe)\n",
        "    for epoch in range(epochs):\n",
        "        classifier.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier(train_feats.to(device))\n",
        "        loss = criterion(outputs, train_labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    classifier.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = classifier(test_feats.to(device))\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        acc = (preds.cpu() == test_labels).float().mean().item() * 100\n",
        "    return acc\n",
        "\n",
        "# Evaluate linear probe accuracy from different transformer layers (0 = before blocks, depth = after all blocks)\n",
        "probe_results = {}\n",
        "for layer_idx in range(len(model_vit.blocks) + 1):\n",
        "    acc = train_linear_probe(model_vit, train_loader_full, test_loader_full, layer_idx, device, epochs=5, lr=1e-3)\n",
        "    probe_results[layer_idx] = acc\n",
        "    print(f\"Layer {layer_idx}: Linear Probe Accuracy = {acc:.2f}%\")\n",
        "\n",
        "# Plot the linear probe accuracy vs. layer index\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(list(probe_results.keys()), list(probe_results.values()), marker='o')\n",
        "plt.xlabel(\"Layer Index (0 = Before Blocks, Final = After all Blocks)\")\n",
        "plt.ylabel(\"Linear Probe Accuracy (%)\")\n",
        "plt.title(\"CLS Token Classification Accuracy vs. Model Layer\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oNXY7ypzlMr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 6"
      ],
      "metadata": {
        "id": "1JEukbY_u-MM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_attention_maps(model, dataloader, device, num_images_per_class=2, num_layers_to_show=None):\n",
        "    \"\"\"\n",
        "    For 2 test images per class, classifies them and visualizes:\n",
        "    - the original image,\n",
        "    - and the average CLS token attention map from each transformer block.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    # Collect 2 images per class from the test loader\n",
        "    images_per_class = {i: [] for i in range(10)}\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            for img, label in zip(imgs, labels):\n",
        "                lbl = label.item()\n",
        "                if len(images_per_class[lbl]) < num_images_per_class:\n",
        "                    images_per_class[lbl].append(img)\n",
        "            if all(len(images_per_class[i]) >= num_images_per_class for i in range(10)):\n",
        "                break\n",
        "\n",
        "    # Flatten selected images with their ground truth labels\n",
        "    selected = []\n",
        "    for cls in range(10):\n",
        "        for img in images_per_class[cls]:\n",
        "            selected.append((img, cls))\n",
        "\n",
        "    # Process each selected image\n",
        "    for idx, (img, gt) in enumerate(selected):\n",
        "        img_batch = img.unsqueeze(0).to(device)  # Shape: (1, C, H, W)\n",
        "        logits, attn_maps = model(img_batch, return_attention=True)\n",
        "        pred = logits.argmax(dim=1).item()\n",
        "\n",
        "        # Determine how many layers to show\n",
        "        num_layers = len(attn_maps)\n",
        "        if num_layers_to_show is None:\n",
        "            num_layers_to_show = num_layers\n",
        "\n",
        "        # Set up subplots: 1 for original image, plus one per layer to show CLS token attention\n",
        "        fig, axes = plt.subplots(1, num_layers_to_show + 1, figsize=(3 * (num_layers_to_show + 1), 3))\n",
        "\n",
        "        # Plot the original image\n",
        "        # Convert from (C, H, W) to (H, W, C)\n",
        "        orig_img = img.cpu().numpy().transpose(1, 2, 0)\n",
        "        # Optionally, unnormalize if needed; here we assume the image is in [0,1]\n",
        "        axes[0].imshow(np.clip(orig_img, 0, 1))\n",
        "        axes[0].set_title(f\"Orig\\nGT: {gt}\\nPred: {pred}\")\n",
        "        axes[0].axis(\"off\")\n",
        "\n",
        "        # For each transformer block, compute and plot the average attention from the CLS token\n",
        "        for i in range(num_layers_to_show):\n",
        "            # Each attn map: shape (1, num_heads, seq_len, seq_len)\n",
        "            attn = attn_maps[i].squeeze(0)  # Now shape: (num_heads, seq_len, seq_len)\n",
        "            attn_avg = attn.mean(dim=0)      # Average over heads → shape: (seq_len, seq_len)\n",
        "            # The CLS token is at index 0; skip it for patch-level attention visualization.\n",
        "            # Compute grid size from number of patches: seq_len = 1 + num_patches, so grid = sqrt(num_patches)\n",
        "            num_patches = attn_avg.shape[0] - 1\n",
        "            grid_size = int(np.sqrt(num_patches))\n",
        "            # Extract attention from the CLS token to the patch tokens and reshape to grid\n",
        "            cls_attn = attn_avg[0, 1:].reshape(grid_size, grid_size)\n",
        "            im = axes[i+1].imshow(cls_attn.cpu().numpy(), cmap=\"viridis\")\n",
        "            axes[i+1].set_title(f\"Layer {i+1}\\nCLS Attn\")\n",
        "            axes[i+1].axis(\"off\")\n",
        "            fig.colorbar(im, ax=axes[i+1], fraction=0.046, pad=0.04)\n",
        "\n",
        "        plt.suptitle(f\"Test Image {idx+1} | GT: {gt} | Pred: {pred}\", fontsize=12)\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "        plt.show()\n",
        "\n",
        "# Run visualization: take 2 test images per class from test_loader_full, and visualize attention maps\n",
        "visualize_attention_maps(model_vit, test_loader_full, device, num_images_per_class=2)\n"
      ],
      "metadata": {
        "id": "EfOVGvxgu1vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OhielQrq2Cpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kGFBFNYZ2DsJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}